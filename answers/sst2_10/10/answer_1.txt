To select the most informative instances for labeling in an active learning context, I would follow these steps:

1. **Diversity**: Choose instances that represent a wide range of sentiments and styles. This helps in building a more robust model.

2. **Ambiguity**: Select instances where the sentiment is not clear-cut. These are usually more informative for training purposes.

3. **Representativeness**: Include instances that are representative of the common themes or patterns in the dataset.

4. **Uniqueness**: Opt for instances that are unique or rare in the context of the dataset, which can help the model learn from less frequent cases.

5. **Complexity**: Prioritize instances that contain complex structures or ideas, as they can provide more learning opportunities.

Based on these criteria, here's my selection:

- **0**: "plays like some corny television production from a bygone era" (Ambiguity, Complexity)
- **6**: "the sentimental cliches mar an otherwise excellent film" (Ambiguity, Complexity)
- **10**: "miyazaki has created such a vibrant, colorful world..." (Representativeness, Uniqueness)
- **14**: "(kline's) utterly convincing -- and deeply appealing..." (Diversity, Complexity)
- **20**: "it's funny and human and really pretty damned wonderful, all at once" (Ambiguity, Diversity)
- **32**: "a rich and intelligent film that uses its pulpy core conceit..." (Uniqueness, Complexity)
- **41**: "'s kind of sad that so many people put so much time and energy into this turkey" (Diversity, Uniqueness)
- **57**: "the big finish is a bit like getting all excited about a chocolate eclair..." (Complexity, Uniqueness)
- **66**: "without resorting to camp or parody, haynes (like sirk, but differently) has transformed..." (Diversity, Complexity)
- **80**: "'s hard to imagine any recent film, independent or otherwise, that makes as much of a mess as this one" (Ambiguity, Complexity)

Therefore, the selected instances are: **0, 6, 10, 14, 20, 32, 41, 57, 66, 80**.